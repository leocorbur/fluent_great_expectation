{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation Workflow\n",
    "The following diagram illustrates the end-to-end GX data validation workflow that I will implement.</br>\n",
    "<img src=\"src/workflow.png\" alt=\"Workflow\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install GX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install GX\n",
    "# %pip install great_expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GX\n",
    "import great_expectations as gx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Data Context\n",
    "### Default Project Structure\n",
    "``` bash\n",
    "gx/\n",
    "├── checkpoints\n",
    "├── expectations\n",
    "├── plugins\n",
    "├── profilers\n",
    "└── uncommitted\n",
    "    ├── data_docs\n",
    "    ├── validations\n",
    "    └── config_variables.yml\n",
    "├── .gitignore\n",
    "├── great_expectations.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "  ___              _     ___                  _        _   _\n",
      " / __|_ _ ___ __ _| |_  | __|_ ___ __  ___ __| |_ __ _| |_(_)___ _ _  ___\n",
      "| (_ | '_/ -_) _` |  _| | _|\\ \\ / '_ \\/ -_) _|  _/ _` |  _| / _ \\ ' \\(_-<\n",
      " \\___|_| \\___\\__,_|\\__| |___/_\\_\\ .__/\\___\\__|\\__\\__,_|\\__|_\\___/_||_/__/\n",
      "                                |_|\n",
      "             ~ Always know what to expect from your data ~\n",
      "\u001b[0m\n",
      "Let's create a new Data Context to hold your project configuration.\n",
      "\n",
      "Great Expectations will create a new directory with the following structure:\n",
      "\n",
      "    great_expectations\n",
      "    |-- great_expectations.yml\n",
      "    |-- expectations\n",
      "    |-- checkpoints\n",
      "    |-- plugins\n",
      "    |-- .gitignore\n",
      "    |-- uncommitted\n",
      "        |-- config_variables.yml\n",
      "        |-- data_docs\n",
      "        |-- validations\n",
      "\n",
      "OK to proceed? [Y/n]: \n",
      "================================================================================\n",
      "\n",
      "\u001b[36mCongratulations! You are now ready to customize your Great Expectations configuration.\u001b[0m\n",
      "\n",
      "\u001b[36mYou can customize your configuration in many ways. Here are some examples:\u001b[0m\n",
      "\n",
      "  \u001b[36mUse the CLI to:\u001b[0m\n",
      "    - Run `\u001b[32mgreat_expectations datasource new\u001b[0m` to connect to your data.\n",
      "    - Run `\u001b[32mgreat_expectations checkpoint new <checkpoint_name>\u001b[0m` to bundle data with Expectation Suite(s) in a Checkpoint for later re-validation.\n",
      "    - Run `\u001b[32mgreat_expectations suite --help\u001b[0m` to create, edit, list, profile Expectation Suites.\n",
      "    - Run `\u001b[32mgreat_expectations docs --help\u001b[0m` to build and manage Data Docs sites.\n",
      "\n",
      "  \u001b[36mEdit your configuration in great_expectations.yml to:\u001b[0m\n",
      "    - Move Stores to the cloud\n",
      "    - Add Slack notifications, PagerDuty alerts, etc.\n",
      "    - Customize your Data Docs\n",
      "\n",
      "\u001b[36mPlease see our documentation for more configuration options!\u001b[0m\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Initialize GX\n",
    "# After running, you will check the project structure created\n",
    "!echo y | great_expectations init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this method to instantiating and returning a Data Context\n",
    "context = gx.get_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide a name for the datasource and \n",
    "# specify the path to the data folder\n",
    "datasource_name = \"nyc_taxy\"\n",
    "path_foder = 'data'\n",
    "\n",
    "# Connect to the data\n",
    "datasource = context.sources.add_pandas_filesystem(\n",
    "    name = datasource_name, \n",
    "    base_directory = path_foder\n",
    ")\n",
    "\n",
    "# Upon executing the code above, you will observe the creation \n",
    "# of the fluent data source section in gx/great_expectations.yml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data Asset and \n",
    "# specify a regular expression to identify relevant files\n",
    "asset_name = f\"{datasource_name}_11_2013\"\n",
    "batching_regex = r\"batch_(?P<batch>\\d{1}).parquet\"\n",
    "\n",
    "asset = datasource.add_parquet_asset(name=asset_name,\n",
    "                                     batching_regex=batching_regex,\n",
    "                                     order_by=[\"batch\"], )\n",
    "\n",
    "# You can check the great_expectations.yml file again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': 'data/batch_0.parquet', 'reader_method': 'read_parquet', 'reader_options': {}}\n",
      "{'path': 'data/batch_1.parquet', 'reader_method': 'read_parquet', 'reader_options': {}}\n",
      "{'path': 'data/batch_2.parquet', 'reader_method': 'read_parquet', 'reader_options': {}}\n",
      "{'path': 'data/batch_3.parquet', 'reader_method': 'read_parquet', 'reader_options': {}}\n",
      "{'path': 'data/batch_4.parquet', 'reader_method': 'read_parquet', 'reader_options': {}}\n"
     ]
    }
   ],
   "source": [
    "# Verify the Data Asset works using Batch Request methods.\n",
    "batch_request = asset.build_batch_request()\n",
    "batches_list = asset.get_batch_list_from_batch_request(batch_request)\n",
    "for batch in batches_list:\n",
    "    print(batch.batch_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'data/batch_4.parquet',\n",
       " 'reader_method': 'read_parquet',\n",
       " 'reader_options': {}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_list[4].batch_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will use the add_expectation_suite() method to create an ExpectationSuite.\n",
    "expectation_name = \"nyc_expectations\"\n",
    "suite = context.add_expectation_suite(expectation_suite_name=expectation_name)\n",
    "\n",
    "# After running, check the config file in gx/expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to add specific expectations to the suite\n",
    "# For this sample, the chosen expectations were expect_column_values_to_not_be_null \n",
    "# and expect_column_values_to_be_between.\n",
    "# The method to add expectations is append_expectation.\n",
    "\n",
    "def add_null_expectation(suite, column):\n",
    "    \"\"\"\n",
    "    Add an expectation to the suite to check if the specified column values are not null.\n",
    "    \n",
    "    Parameters:\n",
    "    - suite: The expectation suite to which the expectation will be added.\n",
    "    - column: The column for which the expectation will be applied.\n",
    "    \"\"\"\n",
    "    suite.append_expectation({\n",
    "        \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
    "        \"kwargs\": {\"column\": column}\n",
    "    })\n",
    "\n",
    "def add_between_expectation(suite, column, min_value, max_value):\n",
    "    \"\"\"\n",
    "    Add an expectation to the suite to check if the specified column values fall within a given range.\n",
    "    \n",
    "    Parameters:\n",
    "    - suite: The expectation suite to which the expectation will be added.\n",
    "    - column: The column for which the expectation will be applied.\n",
    "    - min_value: The minimum expected value for the column.\n",
    "    - max_value: The maximum expected value for the column.\n",
    "    \"\"\"\n",
    "    suite.append_expectation({\n",
    "        \"expectation_type\": \"expect_column_values_to_be_between\",\n",
    "        \"kwargs\": {\"column\": column, \"min_value\": min_value, \"max_value\": max_value}\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add expectations for null values\n",
    "add_null_expectation(suite, \"request_datetime\")\n",
    "add_null_expectation(suite, \"on_scene_datetime\")\n",
    "add_null_expectation(suite, \"pickup_datetime\")\n",
    "add_null_expectation(suite, \"dropoff_datetime\")\n",
    "\n",
    "# Add expectations for value ranges\n",
    "add_between_expectation(suite, \"PULocationID\", 1, 265)\n",
    "add_between_expectation(suite, \"DOLocationID\", 1, 265)\n",
    "add_between_expectation(suite, \"base_passenger_fare\", 5, 500)\n",
    "add_between_expectation(suite, \"driver_pay\", 5, 500)\n",
    "add_between_expectation(suite, \"trip_miles\", 0.2, 100)\n",
    "add_between_expectation(suite, \"trip_time\", 500, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/leonelcortez/Desktop/nyc_gx/gx/expectations/nyc_expectations.json'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the expectations suite for later use.\n",
    "context.save_expectation_suite(suite)\n",
    "\n",
    "# After running, you can inspect the file to view the added expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Batch(datasource=PandasFilesystemDatasource(type='pandas_filesystem', name='nyc_taxy', id=None, assets=[ParquetAsset(name='nyc_taxy_11_2013', type='parquet', id=None, order_by=[Sorter(key='batch', reverse=False)], batch_metadata={}, batching_regex=re.compile('batch_(?P<batch>\\\\d{1}).parquet'), connect_options={}, splitter=None, engine='auto', columns=None, storage_options=None, use_nullable_dtypes=None, dtype_backend=None, kwargs=None)], base_directory=PosixPath('data'), data_context_root_directory=None), data_asset=ParquetAsset(name='nyc_taxy_11_2013', type='parquet', id=None, order_by=[Sorter(key='batch', reverse=False)], batch_metadata={}, batching_regex=re.compile('batch_(?P<batch>\\\\d{1}).parquet'), connect_options={}, splitter=None, engine='auto', columns=None, storage_options=None, use_nullable_dtypes=None, dtype_backend=None, kwargs=None), batch_request=BatchRequest(datasource_name='nyc_taxy', data_asset_name='nyc_taxy_11_2013', options={'path': 'batch_0.parquet', 'batch': '0'}), data=<great_expectations.execution_engine.pandas_batch_data.PandasBatchData object at 0x17b06bd90>, id='nyc_taxy-nyc_taxy_11_2013-batch_0', metadata={'path': 'batch_0.parquet', 'batch': '0'}, batch_markers={'ge_load_time': '20240220T140320.174895Z', 'pandas_data_fingerprint': '33aa923ceeb8b87e2065dd2d6bb48aff'}, batch_spec={'path': 'data/batch_0.parquet', 'reader_method': 'read_parquet', 'reader_options': {}}, batch_definition={'datasource_name': 'nyc_taxy', 'data_connector_name': 'fluent', 'data_asset_name': 'nyc_taxy_11_2013', 'batch_identifiers': {'path': 'batch_0.parquet', 'batch': '0'}}),\n",
       " Batch(datasource=PandasFilesystemDatasource(type='pandas_filesystem', name='nyc_taxy', id=None, assets=[ParquetAsset(name='nyc_taxy_11_2013', type='parquet', id=None, order_by=[Sorter(key='batch', reverse=False)], batch_metadata={}, batching_regex=re.compile('batch_(?P<batch>\\\\d{1}).parquet'), connect_options={}, splitter=None, engine='auto', columns=None, storage_options=None, use_nullable_dtypes=None, dtype_backend=None, kwargs=None)], base_directory=PosixPath('data'), data_context_root_directory=None), data_asset=ParquetAsset(name='nyc_taxy_11_2013', type='parquet', id=None, order_by=[Sorter(key='batch', reverse=False)], batch_metadata={}, batching_regex=re.compile('batch_(?P<batch>\\\\d{1}).parquet'), connect_options={}, splitter=None, engine='auto', columns=None, storage_options=None, use_nullable_dtypes=None, dtype_backend=None, kwargs=None), batch_request=BatchRequest(datasource_name='nyc_taxy', data_asset_name='nyc_taxy_11_2013', options={'path': 'batch_1.parquet', 'batch': '1'}), data=<great_expectations.execution_engine.pandas_batch_data.PandasBatchData object at 0x17faaf710>, id='nyc_taxy-nyc_taxy_11_2013-batch_1', metadata={'path': 'batch_1.parquet', 'batch': '1'}, batch_markers={'ge_load_time': '20240220T140321.058828Z', 'pandas_data_fingerprint': '93147cbcce31f55f5044bde1d1e98469'}, batch_spec={'path': 'data/batch_1.parquet', 'reader_method': 'read_parquet', 'reader_options': {}}, batch_definition={'datasource_name': 'nyc_taxy', 'data_connector_name': 'fluent', 'data_asset_name': 'nyc_taxy_11_2013', 'batch_identifiers': {'path': 'batch_1.parquet', 'batch': '1'}}),\n",
       " Batch(datasource=PandasFilesystemDatasource(type='pandas_filesystem', name='nyc_taxy', id=None, assets=[ParquetAsset(name='nyc_taxy_11_2013', type='parquet', id=None, order_by=[Sorter(key='batch', reverse=False)], batch_metadata={}, batching_regex=re.compile('batch_(?P<batch>\\\\d{1}).parquet'), connect_options={}, splitter=None, engine='auto', columns=None, storage_options=None, use_nullable_dtypes=None, dtype_backend=None, kwargs=None)], base_directory=PosixPath('data'), data_context_root_directory=None), data_asset=ParquetAsset(name='nyc_taxy_11_2013', type='parquet', id=None, order_by=[Sorter(key='batch', reverse=False)], batch_metadata={}, batching_regex=re.compile('batch_(?P<batch>\\\\d{1}).parquet'), connect_options={}, splitter=None, engine='auto', columns=None, storage_options=None, use_nullable_dtypes=None, dtype_backend=None, kwargs=None), batch_request=BatchRequest(datasource_name='nyc_taxy', data_asset_name='nyc_taxy_11_2013', options={'path': 'batch_2.parquet', 'batch': '2'}), data=<great_expectations.execution_engine.pandas_batch_data.PandasBatchData object at 0x17fabe090>, id='nyc_taxy-nyc_taxy_11_2013-batch_2', metadata={'path': 'batch_2.parquet', 'batch': '2'}, batch_markers={'ge_load_time': '20240220T140321.818700Z', 'pandas_data_fingerprint': '749d30c8e105b8ee2af46a57cb7c9756'}, batch_spec={'path': 'data/batch_2.parquet', 'reader_method': 'read_parquet', 'reader_options': {}}, batch_definition={'datasource_name': 'nyc_taxy', 'data_connector_name': 'fluent', 'data_asset_name': 'nyc_taxy_11_2013', 'batch_identifiers': {'path': 'batch_2.parquet', 'batch': '2'}}),\n",
       " Batch(datasource=PandasFilesystemDatasource(type='pandas_filesystem', name='nyc_taxy', id=None, assets=[ParquetAsset(name='nyc_taxy_11_2013', type='parquet', id=None, order_by=[Sorter(key='batch', reverse=False)], batch_metadata={}, batching_regex=re.compile('batch_(?P<batch>\\\\d{1}).parquet'), connect_options={}, splitter=None, engine='auto', columns=None, storage_options=None, use_nullable_dtypes=None, dtype_backend=None, kwargs=None)], base_directory=PosixPath('data'), data_context_root_directory=None), data_asset=ParquetAsset(name='nyc_taxy_11_2013', type='parquet', id=None, order_by=[Sorter(key='batch', reverse=False)], batch_metadata={}, batching_regex=re.compile('batch_(?P<batch>\\\\d{1}).parquet'), connect_options={}, splitter=None, engine='auto', columns=None, storage_options=None, use_nullable_dtypes=None, dtype_backend=None, kwargs=None), batch_request=BatchRequest(datasource_name='nyc_taxy', data_asset_name='nyc_taxy_11_2013', options={'path': 'batch_3.parquet', 'batch': '3'}), data=<great_expectations.execution_engine.pandas_batch_data.PandasBatchData object at 0x17fabf8d0>, id='nyc_taxy-nyc_taxy_11_2013-batch_3', metadata={'path': 'batch_3.parquet', 'batch': '3'}, batch_markers={'ge_load_time': '20240220T140322.530240Z', 'pandas_data_fingerprint': '590f6cb19815be6fe3154c77c879afc7'}, batch_spec={'path': 'data/batch_3.parquet', 'reader_method': 'read_parquet', 'reader_options': {}}, batch_definition={'datasource_name': 'nyc_taxy', 'data_connector_name': 'fluent', 'data_asset_name': 'nyc_taxy_11_2013', 'batch_identifiers': {'path': 'batch_3.parquet', 'batch': '3'}}),\n",
       " Batch(datasource=PandasFilesystemDatasource(type='pandas_filesystem', name='nyc_taxy', id=None, assets=[ParquetAsset(name='nyc_taxy_11_2013', type='parquet', id=None, order_by=[Sorter(key='batch', reverse=False)], batch_metadata={}, batching_regex=re.compile('batch_(?P<batch>\\\\d{1}).parquet'), connect_options={}, splitter=None, engine='auto', columns=None, storage_options=None, use_nullable_dtypes=None, dtype_backend=None, kwargs=None)], base_directory=PosixPath('data'), data_context_root_directory=None), data_asset=ParquetAsset(name='nyc_taxy_11_2013', type='parquet', id=None, order_by=[Sorter(key='batch', reverse=False)], batch_metadata={}, batching_regex=re.compile('batch_(?P<batch>\\\\d{1}).parquet'), connect_options={}, splitter=None, engine='auto', columns=None, storage_options=None, use_nullable_dtypes=None, dtype_backend=None, kwargs=None), batch_request=BatchRequest(datasource_name='nyc_taxy', data_asset_name='nyc_taxy_11_2013', options={'path': 'batch_4.parquet', 'batch': '4'}), data=<great_expectations.execution_engine.pandas_batch_data.PandasBatchData object at 0x17fac6dd0>, id='nyc_taxy-nyc_taxy_11_2013-batch_4', metadata={'path': 'batch_4.parquet', 'batch': '4'}, batch_markers={'ge_load_time': '20240220T140323.230705Z', 'pandas_data_fingerprint': '8486f9177481b832ac7346b04d6706bd'}, batch_spec={'path': 'data/batch_4.parquet', 'reader_method': 'read_parquet', 'reader_options': {}}, batch_definition={'datasource_name': 'nyc_taxy', 'data_connector_name': 'fluent', 'data_asset_name': 'nyc_taxy_11_2013', 'batch_identifiers': {'path': 'batch_4.parquet', 'batch': '4'}})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before running a Checkpoint, take note next:\n",
    "# You have a list of batches (batches_list).\n",
    "batches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So you'll convert the list of Batches into a list of Batch Requests\n",
    "batch_request_list = [batch.batch_request for batch in batches_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BatchRequest(datasource_name='nyc_taxy', data_asset_name='nyc_taxy_11_2013', options={'path': 'batch_0.parquet', 'batch': '0'}),\n",
       " BatchRequest(datasource_name='nyc_taxy', data_asset_name='nyc_taxy_11_2013', options={'path': 'batch_1.parquet', 'batch': '1'}),\n",
       " BatchRequest(datasource_name='nyc_taxy', data_asset_name='nyc_taxy_11_2013', options={'path': 'batch_2.parquet', 'batch': '2'}),\n",
       " BatchRequest(datasource_name='nyc_taxy', data_asset_name='nyc_taxy_11_2013', options={'path': 'batch_3.parquet', 'batch': '3'}),\n",
       " BatchRequest(datasource_name='nyc_taxy', data_asset_name='nyc_taxy_11_2013', options={'path': 'batch_4.parquet', 'batch': '4'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_request_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a validations list\n",
    "validations = [\n",
    "    {\"batch_request\": batch.batch_request, \n",
    "     \"expectation_suite_name\": expectation_name}\n",
    "    for batch in batches_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Checkpoint\n",
    "checkpoint_name = \"BatchValidationPoint\"\n",
    "checkpoint = context.add_or_update_checkpoint(\n",
    "    name=checkpoint_name, \n",
    "    validations=validations\n",
    ")\n",
    "\n",
    "# Upon execution, a new checkpoint file named \"BatchValidationPoint\" will be created in gx/checkpoints.\n",
    "# This file will contain configuration for each data batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f872824b10a043aa8af19bf0520202ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5136120b9a4745598f26e0a75a8efc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243de7fcb60443c698f39dc326bd974b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844c31197b694f3c8b1741e0f5a99c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd03a3ce8564fedbff05643b9a8ddfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the Checkpoint\n",
    "checkpoint_result = checkpoint.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluated_expectations': 10,\n",
       " 'successful_expectations': 5,\n",
       " 'unsuccessful_expectations': 5,\n",
       " 'success_percent': 50.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_identifier = next(iter(checkpoint_result['run_results']))\n",
    "checkpoint_result['run_results'][run_identifier]['validation_result']['statistics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You observed that the checkpoint result showed a 50% success rate.\n",
    "# Run the following code to examine the validation results in more detail.\n",
    "# Build and view the Validation Results as Data Docs.\n",
    "context.build_data_docs()\n",
    "context.open_data_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/gx_doc.png\" alt=\"doc\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/gx_doc_result.png\" alt=\"result\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Validator\n",
    "You can use a Validator to interactively create your Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e315940004aa4406a580a97c7126b1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>driver_pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-25 18:35:17</td>\n",
       "      <td>2023-11-25 18:38:09</td>\n",
       "      <td>2023-11-25 18:39:34</td>\n",
       "      <td>2023-11-25 19:15:20</td>\n",
       "      <td>36</td>\n",
       "      <td>132</td>\n",
       "      <td>10.50</td>\n",
       "      <td>2146</td>\n",
       "      <td>59.53</td>\n",
       "      <td>45.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-25 18:11:04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-11-25 18:13:29</td>\n",
       "      <td>2023-11-25 18:28:59</td>\n",
       "      <td>69</td>\n",
       "      <td>168</td>\n",
       "      <td>2.96</td>\n",
       "      <td>930</td>\n",
       "      <td>16.73</td>\n",
       "      <td>12.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-25 18:53:13</td>\n",
       "      <td>2023-11-25 18:57:53</td>\n",
       "      <td>2023-11-25 18:59:03</td>\n",
       "      <td>2023-11-25 19:14:06</td>\n",
       "      <td>166</td>\n",
       "      <td>244</td>\n",
       "      <td>3.77</td>\n",
       "      <td>903</td>\n",
       "      <td>19.63</td>\n",
       "      <td>13.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-25 18:57:54</td>\n",
       "      <td>2023-11-25 18:59:06</td>\n",
       "      <td>2023-11-25 18:59:18</td>\n",
       "      <td>2023-11-25 19:13:14</td>\n",
       "      <td>112</td>\n",
       "      <td>80</td>\n",
       "      <td>2.07</td>\n",
       "      <td>836</td>\n",
       "      <td>15.19</td>\n",
       "      <td>10.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-25 18:40:19</td>\n",
       "      <td>2023-11-25 18:40:58</td>\n",
       "      <td>2023-11-25 18:42:59</td>\n",
       "      <td>2023-11-25 18:48:23</td>\n",
       "      <td>249</td>\n",
       "      <td>68</td>\n",
       "      <td>0.77</td>\n",
       "      <td>324</td>\n",
       "      <td>8.40</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0 2023-11-25 18:35:17 2023-11-25 18:38:09 2023-11-25 18:39:34   \n",
       "1 2023-11-25 18:11:04                 NaT 2023-11-25 18:13:29   \n",
       "2 2023-11-25 18:53:13 2023-11-25 18:57:53 2023-11-25 18:59:03   \n",
       "3 2023-11-25 18:57:54 2023-11-25 18:59:06 2023-11-25 18:59:18   \n",
       "4 2023-11-25 18:40:19 2023-11-25 18:40:58 2023-11-25 18:42:59   \n",
       "\n",
       "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  trip_time  \\\n",
       "0 2023-11-25 19:15:20            36           132       10.50       2146   \n",
       "1 2023-11-25 18:28:59            69           168        2.96        930   \n",
       "2 2023-11-25 19:14:06           166           244        3.77        903   \n",
       "3 2023-11-25 19:13:14           112            80        2.07        836   \n",
       "4 2023-11-25 18:48:23           249            68        0.77        324   \n",
       "\n",
       "   base_passenger_fare  driver_pay  \n",
       "0                59.53       45.38  \n",
       "1                16.73       12.74  \n",
       "2                19.63       13.85  \n",
       "3                15.19       10.58  \n",
       "4                 8.40        5.50  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code will take the last batch for validating\n",
    "validator = context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=expectation_name, # optional, if you want to update the expectations made above.\n",
    ")\n",
    "validator.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1dc8c9b86c447e8a2830a31229a3735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": false,\n",
       "  \"result\": {\n",
       "    \"element_count\": 3269250,\n",
       "    \"unexpected_count\": 2834877,\n",
       "    \"unexpected_percent\": 86.71337462720807,\n",
       "    \"partial_unexpected_list\": [\n",
       "      69,\n",
       "      166,\n",
       "      112,\n",
       "      249,\n",
       "      246,\n",
       "      112,\n",
       "      240,\n",
       "      174,\n",
       "      243,\n",
       "      51,\n",
       "      254,\n",
       "      61,\n",
       "      165,\n",
       "      78,\n",
       "      213,\n",
       "      197,\n",
       "      138,\n",
       "      130,\n",
       "      215,\n",
       "      89\n",
       "    ],\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_percent_total\": 86.71337462720807,\n",
       "    \"unexpected_percent_nonmissing\": 86.71337462720807\n",
       "  },\n",
       "  \"meta\": {},\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and run an Expectation\n",
    "validator.expect_column_values_to_be_between(\"PULocationID\",3,45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save or update Expectations for future use \n",
    "# validator.save_expectation_suite(discard_failed_expectations=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
